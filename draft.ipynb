{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0020f3749104cef82aabd509765eb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dd7732a211453cb3e208dd9a7024b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to processed_sentences.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import (\n",
    "    mixed_language_word_seg,\n",
    "    random_translate,\n",
    "    clean_mixed_language_sentence,\n",
    "    compare_sentences,\n",
    "    compute_token_nll,\n",
    "    compute_word_nll,\n",
    "    calculate_sentence_perplexity,\n",
    ")\n",
    "\n",
    "# Parameters\n",
    "input_csv = \"data/ASDEND_filtered.csv\"\n",
    "output_data = []\n",
    "n_translations = 5  # Number of translated sentences to generate for each original sentence\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Process each sentence\n",
    "for sentence in df[\"sentence\"][:10]:\n",
    "    original_sentence = \" \".join(mixed_language_word_seg(sentence))\n",
    "    cleaned_original = clean_mixed_language_sentence(original_sentence)\n",
    "    \n",
    "    # Compute properties of the original sentence\n",
    "    original_token_nll = compute_token_nll(cleaned_original)\n",
    "    original_word_nll = compute_word_nll(cleaned_original, mixed_language_word_seg)\n",
    "    original_perplexity = calculate_sentence_perplexity(cleaned_original)\n",
    "    \n",
    "    # Generate and process n translated sentences\n",
    "    for _ in range(n_translations):\n",
    "        translated_sentence = \" \".join(random_translate(mixed_language_word_seg(sentence), 3))\n",
    "        cleaned_translated = clean_mixed_language_sentence(translated_sentence)\n",
    "        \n",
    "        # Compare sentences using Llama\n",
    "        llama_choice = compare_sentences( cleaned_translated,cleaned_original)\n",
    "        \n",
    "        # Compute properties of the translated sentence\n",
    "        translated_token_nll = compute_token_nll(cleaned_translated)\n",
    "        translated_word_nll = compute_word_nll(cleaned_translated, mixed_language_word_seg)\n",
    "        translated_perplexity = calculate_sentence_perplexity(cleaned_translated)\n",
    "        \n",
    "        # Store results in the output list\n",
    "        output_data.append({\n",
    "            \"original\": cleaned_original,\n",
    "            \"transformed\": cleaned_translated,\n",
    "            \"llama_preference\": llama_choice,\n",
    "            \"original_word_nll\": original_word_nll,\n",
    "            \"original_token_nll\": original_token_nll,\n",
    "            \"original_perplexity\": original_perplexity,\n",
    "            \"transformed_word_nll\": translated_word_nll,\n",
    "            \"transformed_token_nll\": translated_token_nll,\n",
    "            \"transformed_perplexity\": translated_perplexity,\n",
    "        })\n",
    "\n",
    "# Convert the output to a DataFrame and save to CSV\n",
    "output_df = pd.DataFrame(output_data)\n",
    "output_csv = \"processed_sentences.csv\"\n",
    "output_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Processing complete. Results saved to {output_csv}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
